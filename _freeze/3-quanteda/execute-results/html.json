{
  "hash": "a93946fdcc0a204059d8fba8279456b6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Quantitative analysis of textual data\neditor_options: \n  chunk_output_type: console\n---\n\n\n- https://tutorials.quanteda.io/introduction/\n\n\n## Introduction\n\nThere are several R packages used for quantitative text analysis, but we will focus specifically on the `{quanteda}` package. So, first install the package from CRAN:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"quanteda\")\n```\n:::\n\n\nSince the release of `{quanteda}` version 3.0, `textstat_*`, `textmodel_*` and `textplot_*` functions are available in separate packages. We will use several of these functions in the chapters below and strongly recommend installing these packages.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"quanteda.textmodels\")\ninstall.packages(\"quanteda.textstats\")\ninstall.packages(\"quanteda.textplots\")\n```\n:::\n\n\nWe will use the `{readtext}` package to read in different types of text data in these tutorials. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"readtext\")\n```\n:::\n\n\n\n## Quantitative data \n\nBefore beginning we need to load the libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(quanteda)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'quanteda' was built under R version 4.4.1\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(readtext)\n```\n:::\n\n\n### Pre-formatted files\n\nIf your text data is stored in a pre-formatted file where one column contains the text and additional columns might store document-level variables (e.g. year, author, or language), you can import this into R using `read_csv()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npath_data <- system.file(\"extdata/\", package = \"readtext\")\ndat_inaug <- read_csv(paste0(path_data, \"/csv/inaugCorpus.csv\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 5 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): texts, President, FirstName\ndbl (1): Year\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nglimpse(dat_inaug)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 5\nColumns: 4\n$ texts     <chr> \"Fellow-Citizens of the Senate and of the House of Represent…\n$ Year      <dbl> 1789, 1793, 1797, 1801, 1805\n$ President <chr> \"Washington\", \"Washington\", \"Adams\", \"Jefferson\", \"Jefferson\"\n$ FirstName <chr> \"George\", \"George\", \"John\", \"Thomas\", \"Thomas\"\n```\n\n\n:::\n:::\n\n\nThe data set is about the inaugural speeches of the US presidents. So as we can see the data set is arranged in tabular form, with 5 rows and 4 columns. The columns are `texts`, `Year`, `President`, and `FirstName`. \n\nAlternatively, you can use the `{readtext}` package to import character (comma- or tab-separated) values. `{readtext}` reads files containing text, along with any associated document-level variables. As an example, consider the following tsv file:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntsv_file <- paste0(path_data, \"/tsv/dailsample.tsv\")\ncat(readLines(tsv_file, n = 4), sep = \"\\n\")  # first 3 lines\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nspeechID\tmemberID\tpartyID\tconstID\ttitle\tdate\tmember_name\tparty_name\tconst_name\tspeech\n1\t977\t22\t158\t1. CEANN COMHAIRLE I gCOIR AN LAE.\t1919-01-21\tCount George Noble, Count Plunkett\tSinn Féin\tRoscommon North\tMolaimse don Dáil Cathal Brugha, an Teachta ó Dhéisibh Phortláirge do bheith mar Cheann Comhairle againn indiu.\n2\t1603\t22\t103\t1. CEANN COMHAIRLE I gCOIR AN LAE.\t1919-01-21\tMr. Pádraic Ó Máille\tSinn Féin\tGalway Connemara\tIs bród mór damhsa cur leis an dtairgsin sin. Air sin do ghaibh CATHAL BRUGHA ceannus na Dála agus adubhairt:-\n3\t116\t22\t178\t1. CEANN COMHAIRLE I gCOIR AN LAE.\t1919-01-21\tMr. Cathal Brugha\tSinn Féin\tWaterford County\t' A cháirde, tá obair thábhachtach le déanamh annso indiu, an obair is tábhachtaighe do rinneadh in Éirinn ón lá tháinic na Gaedhil go hÉirinn, agus is naomhtha an obair í. Daoine go bhfuil dóchas aca as Dia iseadh sinn go léir, daoine a chuireann suim I ndlighthibh Dé, agus dá bhrigh sin budh chóir dúinn congnamh d'iarraidh ar Dhia I gcóir na hoibre atá againn le déanamh. Iarrfad anois ar an sagart is dúthrachtaighe dár mhair riamh I nÉirinn, an tAthair Micheál Ó Flannagáin, guidhe chum an Spiorad Naomh dúinn chum sinn do stiúradh ar ár leas ar an mbóthar atá againn le gabháil. ' ' Agus, a cháirde, pé cineál creidimh atá ag éinne annso, iarrfad ar gach n-aon paidir do chur suas chum Dé, ó íochtar a chroidhe chum cabhair do thabhairt dúinn indiu. Glaodhaim anois ar an Athair Micheál Ó Flannagáin. ' Do tháinig an tATHAIR MICHEÁL Ó FLANNAGÁIN I láthair na Dála agus do léigh an phaidir seo I n-ár ndiaidh: 'Tair, A Spioraid Naomh, ath-líon croidhthe t'fhíoraon, agus adhain ionnta teine do ghrádha. ' ' Cuir chugainn do Spioraid agus cruthóchfar iad agus athnuadhfaidh Tú aghaidh na talmhan.' ' Guidhmís: ' ' A Dhia, do theagaisc croidhthe sa bhfíoraon le lonnradh an Spioraid Naoimh, tabhair dúinn, san Spiorad cheudna, go mblaisfimíd an ceart agus go mbéidh síorgháirdeachais orainn de bhárr a shóláis sin. Tré Íosa Críost ár dTighearna. Ámén'\n```\n\n\n:::\n:::\n\n\nThe document itself in raw format is arranged in tabular form, separated by tabs. Each row contains a \"document\" (in this case, a speech) and the columns contain **document-level** variables. The column that contains the actual speech is named `speech`. To import this using `{readtext}`, you can use the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_dail <- readtext(tsv_file, text_field = \"speech\")\nglimpse(dat_dail)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 33\nColumns: 11\n$ doc_id      <chr> \"dailsample.tsv.1\", \"dailsample.tsv.2\", \"dailsample.tsv.3\"…\n$ text        <chr> \"Molaimse don Dáil Cathal Brugha, an Teachta ó Dhéisibh Ph…\n$ speechID    <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ memberID    <int> 977, 1603, 116, 116, 116, 116, 496, 116, 116, 2095, 116, 1…\n$ partyID     <int> 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22…\n$ constID     <int> 158, 103, 178, 178, 178, 178, 46, 178, 178, 139, 178, 178,…\n$ title       <chr> \"1. CEANN COMHAIRLE I gCOIR AN LAE.\", \"1. CEANN COMHAIRLE …\n$ date        <chr> \"1919-01-21\", \"1919-01-21\", \"1919-01-21\", \"1919-01-21\", \"1…\n$ member_name <chr> \"Count George Noble, Count Plunkett\", \"Mr. Pádraic Ó Máill…\n$ party_name  <chr> \"Sinn Féin\", \"Sinn Féin\", \"Sinn Féin\", \"Sinn Féin\", \"Sinn …\n$ const_name  <chr> \"Roscommon North\", \"Galway Connemara\", \"Waterford County\",…\n```\n\n\n:::\n:::\n\n\n### Multiple text files\n\nA second option to import data is to load multiple text files at once that are stored in the same folder or subfolders. Again, `path_data` is the location of sample files on your computer. Unlike the pre-formatted files, individual text files usually do not contain document-level variables. However, you can create document-level variables using the `{readtext}` package.\n\nThe directory `/txt/UDHR` contains text files (\".txt\") of the Universal Declaration of Human Rights in 13 languages. \n\n\n::: {.cell}\n\n```{.r .cell-code}\npath_udhr <- paste0(path_data, \"/txt/UDHR\")\nlist.files(path_udhr)  # list the files in this folder\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"UDHR_chinese.txt\"    \"UDHR_czech.txt\"      \"UDHR_danish.txt\"    \n [4] \"UDHR_english.txt\"    \"UDHR_french.txt\"     \"UDHR_georgian.txt\"  \n [7] \"UDHR_greek.txt\"      \"UDHR_hungarian.txt\"  \"UDHR_icelandic.txt\" \n[10] \"UDHR_irish.txt\"      \"UDHR_japanese.txt\"   \"UDHR_russian.txt\"   \n[13] \"UDHR_vietnamese.txt\"\n```\n\n\n:::\n:::\n\n\nEach one of these txt files contains the text of the UDHR in the specific language.\nFor instance, to inspect what each one of these files contain, we do the following:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# just first 5 lines\ncat(readLines(file.path(path_udhr, \"UDHR_chinese.txt\"), n = 5), sep = \"\\n\")  \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n世界人权宣言\n联合国大会一九四八年十二月十日第217A(III)号决议通过并颁布 1948 年 12 月 10 日， 联 合 国 大 会 通 过 并 颁 布《 世 界 人 权 宣 言》。 这 一 具 有 历 史 意 义 的《 宣 言》 颁 布 后， 大 会 要 求 所 有 会 员 国 广 为 宣 传， 并 且“ 不 分 国 家 或 领 土 的 政 治 地 位 , 主 要 在 各 级 学 校 和 其 他 教 育 机 构 加 以 传 播、 展 示、 阅 读 和 阐 述。” 《 宣 言 》 全 文 如 下： 序言 鉴于对人类家庭所有成员的固有尊严及其平等的和不移的权利的 承 认, 乃 是 世 界 自 由、 正 义 与 和 平 的 基 础, 鉴 于 对 人 权 的 无 视 和 侮 蔑 已 发 展 为 野 蛮 暴 行, 这 些 暴 行 玷 污 了 人 类 的 良 心, 而 一 个 人 人 享 有 言 论 和 信 仰 自 由 并 免 予 恐 惧 和 匮 乏 的 世 界 的 来 临, 已 被 宣 布 为 普 通 人 民 的 最 高 愿 望, 鉴 于 为 使 人 类 不 致 迫 不 得 已 铤 而 走 险 对 暴 政 和 压 迫 进 行 反 叛, 有 必 要 使 人 权 受 法 治 的 保 护, 鉴 于 有 必 要 促 进 各 国 间 友 好 关 系 的 发 展, 鉴于各联合国国家的人民已在联合国宪章中重申他们对基本人 权、 人 格 尊 严 和 价 值 以 及 男 女 平 等 权 利 的 信 念, 并 决 心 促 成 较 大 自 由 中 的 社 会 进 步 和 生 活 水 平 的 改 善, 鉴于各会员国业已誓愿同联合国合作以促进对人权和基本自由的 普 遍 尊 重 和 遵 行, 鉴于对这些权利和自由的普遍了解对于这个誓愿的充分实现具有 很 大 的 重 要 性, 因 此 现 在, 大 会, 发 布 这 一 世 界 人 权 宣 言 , 作 为 所 有 人 民 和 所 有 国 家 努 力 实 现 的 共 同 标 准, 以 期 每 一 个 人 和 社 会 机 构 经 常 铭 念 本 宣 言, 努 力 通 过 教 诲 和 教 育 促 进 对 权 利 和 自 由 的 尊 重, 并 通 过 国 家 的 和 国 际 的 渐 进 措 施, 使 这 些 权 利 和 自 由 在 各 会 员 国 本 身 人 民 及 在 其 管 辖 下 领 土 的 人 民 中 得 到 普 遍 和 有 效 的 承 认 和 遵 行; 第一条\n\n\f人 人 生 而 自 由, 在 尊 严 和 权 利 上 一 律 平 等。 他 们 赋 有 理 性 和 良 心, 并 应 以 兄 弟 关 系 的 精 神 相 对 待。 第二条 人 人 有 资 格 享 有 本 宣 言 所 载 的 一 切 权 利 和 自 由, 不 分 种 族、 肤 色、 性 别、 语 言、 宗 教、 政 治 或 其 他 见 解、 国 籍 或 社 会 出 身、 财 产、 出 生 或 其 他 身 分 等 任 何 区 别。 并 且 不 得 因 一 人 所 属 的 国 家 或 领 土 的 政 治 的、 行 政 的 或 者 国 际 的 地 位 之 不 同 而 有 所 区 别, 无 论 该 领 土 是 独 立 领 土、 托 管 领 土、 非 自 治 领 土 或 者 处 于 其 他 任 何 主 权 受 限 制 的 情 况 之 下。 第三条 人 人 有 权 享 有 生 命、 自 由 和 人 身 安 全。 第四条 任 何 人 不 得 使 为 奴 隶 或 奴 役; 一 切 形 式 的 奴 隶 制 度 和 奴 隶 买 卖, 均 应 予 以 禁 止。 第五条 任 何 人 不 得 加 以 酷 刑, 或 施 以 残 忍 的、 不 人 道 的 或 侮 辱 性 的 待 遇 或 刑 罚。 第六条 人 人 在 任 何 地 方 有 权 被 承 认 在 法 律 前 的 人 格。 第七条\n```\n\n\n:::\n:::\n\n\nTo import these files, you can use the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_udhr <- readtext(path_udhr)\nglimpse(dat_udhr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 13\nColumns: 2\n$ doc_id <chr> \"UDHR_chinese.txt\", \"UDHR_czech.txt\", \"UDHR_danish.txt\", \"UDHR_…\n$ text   <chr> \"世界人权宣言\\n联合国大会一九四八年十二月十日第217A(III)号决议…\n```\n\n\n:::\n:::\n\n\n::: {.callout-note}\nIf you are using Windows, you need might need to specify the encoding of the file by adding `encoding = \"utf-8\"`. In this case, imported texts might appear like `<U+4E16><U+754C><U+4EBA><U+6743>` but they indicate that Unicode charactes are imported correctly.\n:::\n\nHere's another example of multiple text files. The directory `/txt/EU_manifestos` contains text files (\".txt\") of the European Union manifestos in different languages. \n\n\n::: {.cell}\n\n```{.r .cell-code}\npath_eu <- paste0(path_data, \"/txt/EU_manifestos/\")\nlist.files(path_eu)  # list the files in this folder\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"EU_euro_2004_de_PSE.txt\" \"EU_euro_2004_de_V.txt\"  \n [3] \"EU_euro_2004_en_PSE.txt\" \"EU_euro_2004_en_V.txt\"  \n [5] \"EU_euro_2004_es_PSE.txt\" \"EU_euro_2004_es_V.txt\"  \n [7] \"EU_euro_2004_fi_V.txt\"   \"EU_euro_2004_fr_PSE.txt\"\n [9] \"EU_euro_2004_fr_V.txt\"   \"EU_euro_2004_gr_V.txt\"  \n[11] \"EU_euro_2004_hu_V.txt\"   \"EU_euro_2004_it_PSE.txt\"\n[13] \"EU_euro_2004_lv_V.txt\"   \"EU_euro_2004_nl_V.txt\"  \n[15] \"EU_euro_2004_pl_V.txt\"   \"EU_euro_2004_se_V.txt\"  \n[17] \"EU_euro_2004_si_V.txt\"  \n```\n\n\n:::\n:::\n\n\nYou can generate document-level variables based on the file names using the `docvarnames` and `docvarsfrom` argument. `dvsep = \"_\"` specifies the value separator in the filenames. `encoding = \"ISO-8859-1\"` determines character encodings of the texts. Notice how the document variables are nicely generated from the file names.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_eu <- readtext(\n  file = path_eu,\n  docvarsfrom = \"filenames\", \n  docvarnames = c(\"unit\", \"context\", \"year\", \"language\", \"party\"),\n  dvsep = \"_\", \n  encoding = \"ISO-8859-1\"\n)\nglimpse(dat_eu)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 17\nColumns: 7\n$ doc_id   <chr> \"EU_euro_2004_de_PSE.txt\", \"EU_euro_2004_de_V.txt\", \"EU_euro_…\n$ text     <chr> \"PES · PSE · SPE European Parliament rue Wiertz B 1047 Brusse…\n$ unit     <chr> \"EU\", \"EU\", \"EU\", \"EU\", \"EU\", \"EU\", \"EU\", \"EU\", \"EU\", \"EU\", \"…\n$ context  <chr> \"euro\", \"euro\", \"euro\", \"euro\", \"euro\", \"euro\", \"euro\", \"euro…\n$ year     <int> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2…\n$ language <chr> \"de\", \"de\", \"en\", \"en\", \"es\", \"es\", \"fi\", \"fr\", \"fr\", \"gr\", \"…\n$ party    <chr> \"PSE\", \"V\", \"PSE\", \"V\", \"PSE\", \"V\", \"V\", \"PSE\", \"V\", \"V\", \"V\"…\n```\n\n\n:::\n:::\n\n\n### JSON\n\nYou can also read JSON files (.json) downloaded from the Twititer stream API. [twitter.json](https://raw.githubusercontent.com/quanteda/tutorials.quanteda.io/master/content/data/twitter.json) is located in data directory of this tutorial package.\n\nThe JSON file looks something like this\n\n```\n{\"created_at\":\"Wed Jun 07 23:30:01 +0000 2017\",\"id\":872596537142116352,\"id_str\":\"872596537142116352\",\"text\":\"@EFC_Jayy UKIP\",\"display_text_range\":[10,14],\n\"source\":\"\\u003ca href=\\\"http:\\/\\/twitter.com\\/download\\/iphone\\\" rel=\\\"nofollow\\\"\\u003eTwitter for iPhone\\u003c\\/a\\u003e\",\"truncated\":false,\"in_reply_to_status_id\":872596176834572288,\n\"in_reply_to_status_id_str\":\"872596176834572288\",\"in_reply_to_user_id\":4556760676,\"in_reply_to_user_id_str\":\"4556760676\",\"in_reply_to_screen_name\":\"EFC_Jayy\",\"user\":{\"id\":863929468984995840,\"id_str\":\"863929468984995840\",\"name\":\"\\u30b8\\u30e7\\u30fc\\u30b8\",\"screen_name\":\"CoysJoji\",\"location\":\"Japan\",\"url\":null,\"description\":null,\"protected\":false,\n\"verified\":false,\"followers_count\":367,\"friends_count\":304,\"listed_count\":1,\"favourites_count\":1260,\"statuses_count\":2930,\"created_at\":\"Mon May 15 01:30:11 +0000 2017\",\"utc_offset\":null,\"time_zone\":null,\"geo_enabled\":false,\"lang\":\"en\",\"contributors_enabled\":false,\"is_translator\":false,\"profile_background_color\":\"F5F8FA\",\"profile_background_image_url\":\"\",\"profile_background_image_url_https\":\"\",\"profile_background_tile\":false,\n\"profile_link_color\":\"1DA1F2\",\"profile_sidebar_border_color\":\"C0DEED\",\"profile_sidebar_fill_color\":\"DDEEF6\",\"profile_text_color\":\"333333\",\"profile_use_background_image\":true,\"profile_image_url\":\"http:\\/\\/pbs.twimg.com\\/profile_images\\/870447188400365568\\/RiR1hbCe_normal.jpg\",\n\"profile_image_url_https\":\"https:\\/\\/pbs.twimg.com\\/profile_images\\/870447188400365568\\/RiR1hbCe_normal.jpg\",\"profile_banner_url\":\"https:\\/\\/pbs.twimg.com\\/profile_banners\\/863929468984995840\\/1494897624\",\"default_profile\":true,\"default_profile_image\":false,\"following\":null,\"follow_request_sent\":null,\"notifications\":null},\"geo\":null,\"coordinates\":null,\n\"place\":null,\"contributors\":null,\"is_quote_status\":false,\"retweet_count\":0,\"favorite_count\":0,\"entities\":{\"hashtags\":[],\"urls\":[],\"user_mentions\":[{\"screen_name\":\"EFC_Jayy\",\"name\":\"\\u274c\\u274c\\u274c\",\"id\":4556760676,\"id_str\":\"4556760676\",\"indices\":[0,9]}],\"symbols\":[]},\"favorited\":false,\"retweeted\":false,\"filter_level\":\"low\",\"lang\":\"en\",\"timestamp_ms\":\"1496878201171\"}\n```\n\nIt's a little hard to parse, but luckily we just leave it to the `{readtext}` package to do the job for us.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_twitter <- readtext(\"../data/twitter.json\", source = \"twitter\")\n```\n:::\n\n\nThe file comes with several metadata for each tweet, such as the number of retweets and likes, the username, time and time zone. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(names(dat_twitter))\n```\n:::\n\n\n```\n## [1] \"doc_id\"         \"text\"           \"retweet_count\"  \"favorite_count\"\n## [5] \"favorited\"      \"truncated\"\n```\n\n### PDF\n\n`readtext()` can also convert and read PDF (\".pdf\") files. The directory `/pdf/UDHR` contains PDF files of the Universal Declaration of Human Rights in 13 languages. Each file looks like this:\n\n![](figures/udhr_sample.png)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_udhr <- readtext(\n  paste0(path_data, \"/pdf/UDHR/*.pdf\"), \n  docvarsfrom = \"filenames\", \n  docvarnames = c(\"document\", \"language\"),\n  sep = \"_\"\n)\nprint(dat_udhr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nreadtext object consisting of 11 documents and 2 docvars.\n# A data frame: 11 × 4\n  doc_id           text                          document language\n  <chr>            <chr>                         <chr>    <chr>   \n1 UDHR_chinese.pdf \"\\\"世界人权宣言\\n\\n联合\\\"...\" UDHR     chinese \n2 UDHR_czech.pdf   \"\\\"VŠEOBECNÁ \\\"...\"           UDHR     czech   \n3 UDHR_danish.pdf  \"\\\"Den 10. de\\\"...\"           UDHR     danish  \n4 UDHR_english.pdf \"\\\"Universal \\\"...\"           UDHR     english \n5 UDHR_french.pdf  \"\\\"Déclaratio\\\"...\"           UDHR     french  \n6 UDHR_greek.pdf   \"\\\"ΟΙΚΟΥΜΕΝΙΚ\\\"...\"           UDHR     greek   \n# ℹ 5 more rows\n```\n\n\n:::\n:::\n\n\n### Microsoft Word\n\nFinally, `readtext()` can import Microsoft Word (\".doc\" and \".docx\") files.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat_word <- readtext(paste0(path_data, \"/word/*.docx\"))\nprint(dat_udhr)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nreadtext object consisting of 11 documents and 2 docvars.\n# A data frame: 11 × 4\n  doc_id           text                          document language\n  <chr>            <chr>                         <chr>    <chr>   \n1 UDHR_chinese.pdf \"\\\"世界人权宣言\\n\\n联合\\\"...\" UDHR     chinese \n2 UDHR_czech.pdf   \"\\\"VŠEOBECNÁ \\\"...\"           UDHR     czech   \n3 UDHR_danish.pdf  \"\\\"Den 10. de\\\"...\"           UDHR     danish  \n4 UDHR_english.pdf \"\\\"Universal \\\"...\"           UDHR     english \n5 UDHR_french.pdf  \"\\\"Déclaratio\\\"...\"           UDHR     french  \n6 UDHR_greek.pdf   \"\\\"ΟΙΚΟΥΜΕΝΙΚ\\\"...\"           UDHR     greek   \n# ℹ 5 more rows\n```\n\n\n:::\n:::\n\n\n## Workflow\n\n`{quanteda}` has three basic types of objects:\n\n1.  Corpus\n    \n    * Saves character strings and variables in a data frame\n    * Combines texts with document-level variables\n\n2.  Tokens\n    \n    * Stores tokens in a list of vectors\n    * More efficient than character strings, but preserves positions of words \n    * Positional (string-of-words) analysis is performed using `textstat_collocations()`, `tokens_ngrams()` and `tokens_select()` or `fcm()` with `window` option\n\n3.  Document-feature matrix (DFM)\n\n    * Represents frequencies of features in documents in a matrix\n    * The most efficient structure, but it does not have information on positions of words \n    * Non-positional (bag-of-words) analysis are profrmed using many of the `textstat_*` and `textmodel_*` functions \n\nText analysis with `{quanteda}` goes through all those three types of objects either explicitly or implicitly.\n\n\n```{mermaid}\n    graph TD\n    D[Text files]\n    V[Document-level variables]\n    C(Corpus)\n    T(Tokens)\n    AP[\"Positional analysis (string-of-words)\"]\n    AN[\"Non-positional analysis (bag-of-words)\"]\n    M(DFM)\n    style C stroke-width:4px\n    style T stroke-width:4px\n    style M stroke-width:4px\n    D --> C\n    V --> C \n    C --> T \n    T --> M\n    T -.-> AP\n    M -.-> AN\n```\n\n\nFor example, if character vectors are given to `dfm()`, it internally constructs corpus and tokens objects before creating a DFM. \n\n### Corpus\n\nYou can create a corpus from various available sources:\n\n1. A character vector consisting of one document per element\n\n2. A data frame consisting of a character vector for documents, and additional vectors for document-level variables\n\n\n\n#### Character vector\n\n`data_char_ukimmig2010` is a named character vector and consists of sections of British election manifestos on immigration and asylum.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(data_char_ukimmig2010)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Named chr [1:9] \"IMMIGRATION: AN UNPARALLELED CRISIS WHICH ONLY THE BNP CAN SOLVE. \\n\\n- At current immigration and birth rates,\"| __truncated__ ...\n - attr(*, \"names\")= chr [1:9] \"BNP\" \"Coalition\" \"Conservative\" \"Greens\" ...\n```\n\n\n:::\n\n```{.r .cell-code}\ncorp_immig <- corpus(\n  data_char_ukimmig2010, \n  docvars = data.frame(party = names(data_char_ukimmig2010))\n)\nprint(corp_immig)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCorpus consisting of 9 documents and 1 docvar.\nBNP :\n\"IMMIGRATION: AN UNPARALLELED CRISIS WHICH ONLY THE BNP CAN S...\"\n\nCoalition :\n\"IMMIGRATION.  The Government believes that immigration has e...\"\n\nConservative :\n\"Attract the brightest and best to our country. Immigration h...\"\n\nGreens :\n\"Immigration. Migration is a fact of life.  People have alway...\"\n\nLabour :\n\"Crime and immigration The challenge for Britain We will cont...\"\n\nLibDem :\n\"firm but fair immigration system Britain has always been an ...\"\n\n[ reached max_ndoc ... 3 more documents ]\n```\n\n\n:::\n\n```{.r .cell-code}\nsummary(corp_immig)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCorpus consisting of 9 documents, showing 9 documents:\n\n         Text Types Tokens Sentences        party\n          BNP  1125   3280        88          BNP\n    Coalition   142    260         4    Coalition\n Conservative   251    499        15 Conservative\n       Greens   322    679        21       Greens\n       Labour   298    683        29       Labour\n       LibDem   251    483        14       LibDem\n           PC    77    114         5           PC\n          SNP    88    134         4          SNP\n         UKIP   346    723        26         UKIP\n```\n\n\n:::\n:::\n\n\n#### Data frame\n\nUsing `read_csv()`, load an example file from `path_data` as a data frame called `dat_inaug`. Note that your file does not need to be formatted as `.csv`. You can build a `{quanteda}` corpus from any file format that R can import as a data frame (see, for instance, the [**rio**](https://cran.r-project.org/web/packages/rio/index.html) package for importing various files as data frames into R).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set path\npath_data <- system.file(\"extdata/\", package = \"readtext\")\n\n# import csv file\ndat_inaug <- read.csv(paste0(path_data, \"/csv/inaugCorpus.csv\"))\nnames(dat_inaug)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"texts\"     \"Year\"      \"President\" \"FirstName\"\n```\n\n\n:::\n:::\n\n\nConstruct a corpus from the \"texts\" column in `dat_inaug`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorp_inaug <- corpus(dat_inaug, text_field = \"texts\")\nprint(corp_inaug)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCorpus consisting of 5 documents and 3 docvars.\ntext1 :\n\"Fellow-Citizens of the Senate and of the House of Representa...\"\n\ntext2 :\n\"Fellow citizens, I am again called upon by the voice of my c...\"\n\ntext3 :\n\"When it was first perceived, in early times, that no middle ...\"\n\ntext4 :\n\"Friends and Fellow Citizens: Called upon to undertake the du...\"\n\ntext5 :\n\"Proceeding, fellow citizens, to that qualification which the...\"\n```\n\n\n:::\n:::\n\n\n#### Document-level variables\n\n`{quanteda}`'s objects keep information associated with documents. They are called \"document-level variables\", or \"docvars\", and are accessed using `docvars()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncorp <- data_corpus_inaugural\nhead(docvars(corp))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Year  President FirstName                 Party\n1 1789 Washington    George                  none\n2 1793 Washington    George                  none\n3 1797      Adams      John            Federalist\n4 1801  Jefferson    Thomas Democratic-Republican\n5 1805  Jefferson    Thomas Democratic-Republican\n6 1809    Madison     James Democratic-Republican\n```\n\n\n:::\n:::\n\n\nIf you want to extract individual elements of document variables, you can specify `field`. Or you could just subset it as you normally would a data.frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndocvars(corp, field = \"Year\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1789 1793 1797 1801 1805 1809 1813 1817 1821 1825 1829 1833 1837 1841 1845\n[16] 1849 1853 1857 1861 1865 1869 1873 1877 1881 1885 1889 1893 1897 1901 1905\n[31] 1909 1913 1917 1921 1925 1929 1933 1937 1941 1945 1949 1953 1957 1961 1965\n[46] 1969 1973 1977 1981 1985 1989 1993 1997 2001 2005 2009 2013 2017 2021\n```\n\n\n:::\n\n```{.r .cell-code}\ncorp$Year\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1789 1793 1797 1801 1805 1809 1813 1817 1821 1825 1829 1833 1837 1841 1845\n[16] 1849 1853 1857 1861 1865 1869 1873 1877 1881 1885 1889 1893 1897 1901 1905\n[31] 1909 1913 1917 1921 1925 1929 1933 1937 1941 1945 1949 1953 1957 1961 1965\n[46] 1969 1973 1977 1981 1985 1989 1993 1997 2001 2005 2009 2013 2017 2021\n```\n\n\n:::\n:::\n\n\nSo that means assignments to *change* document-level variables will work as usual in R. For example, you can change the `Year` variable to a factor (if you wished). And since the output of a `docvars()` function is a data.frame, you could subset or filter as you would a data.frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndocvars(corp) |>\n  filter(Year >= 1990)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Year President FirstName      Party\n1 1993   Clinton      Bill Democratic\n2 1997   Clinton      Bill Democratic\n3 2001      Bush George W. Republican\n4 2005      Bush George W. Republican\n5 2009     Obama    Barack Democratic\n6 2013     Obama    Barack Democratic\n7 2017     Trump Donald J. Republican\n8 2021     Biden Joseph R. Democratic\n```\n\n\n:::\n\n```{.r .cell-code}\n# {quanteda} also provides corpus_subset() function, but since we learnt about\n# dplyr, we can use it here.\n```\n:::\n\n\n\n\n### Tokens\n\n### Document feature matrix\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}