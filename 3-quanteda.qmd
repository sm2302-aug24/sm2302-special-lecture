---
title: Quantitative analysis of textual data
editor_options: 
  chunk_output_type: console
---

- https://tutorials.quanteda.io/introduction/


## Introduction

There are several R packages used for quantitative text analysis, but we will focus specifically on the `{quanteda}` package. So, first install the package from CRAN:

```{r}
#| eval: false
install.packages("quanteda")
```

Since the release of `{quanteda}` version 3.0, `textstat_*`, `textmodel_*` and `textplot_*` functions are available in separate packages. We will use several of these functions in the chapters below and strongly recommend installing these packages.


```{r}
#| eval: false
install.packages("quanteda.textmodels")
install.packages("quanteda.textstats")
install.packages("quanteda.textplots")
```

We will use the `{readtext}` package to read in different types of text data in these tutorials. 


```{r}
#| eval: false
install.packages("readtext")
```


## Quantitative data 

Before beginning we need to load the libraries

```{r}
#| message: false
library(tidyverse)
library(quanteda)
library(readtext)
```

### Pre-formatted files

If your text data is stored in a pre-formatted file where one column contains the text and additional columns might store document-level variables (e.g. year, author, or language), you can import this into R using `read_csv()`.

```{r}
path_data <- system.file("extdata/", package = "readtext")
dat_inaug <- read_csv(paste0(path_data, "/csv/inaugCorpus.csv"))
glimpse(dat_inaug)
```

The data set is about the inaugural speeches of the US presidents. So as we can see the data set is arranged in tabular form, with 5 rows and 4 columns. The columns are `texts`, `Year`, `President`, and `FirstName`. 

Alternatively, you can use the `{readtext}` package to import character (comma- or tab-separated) values. `{readtext}` reads files containing text, along with any associated document-level variables. As an example, consider the following tsv file:

```{r}
tsv_file <- paste0(path_data, "/tsv/dailsample.tsv")
cat(readLines(tsv_file, n = 4), sep = "\n")  # first 3 lines
```

The document itself in raw format is arranged in tabular form, separated by tabs. Each row contains a "document" (in this case, a speech) and the columns contain **document-level** variables. The column that contains the actual speech is named `speech`. To import this using `{readtext}`, you can use the following code:

```{r}
dat_dail <- readtext(tsv_file, text_field = "speech")
glimpse(dat_dail)
```

### Multiple text files

A second option to import data is to load multiple text files at once that are stored in the same folder or subfolders. Again, `path_data` is the location of sample files on your computer. Unlike the pre-formatted files, individual text files usually do not contain document-level variables. However, you can create document-level variables using the `{readtext}` package.

The directory `/txt/UDHR` contains text files (".txt") of the Universal Declaration of Human Rights in 13 languages. 

```{r}
path_udhr <- paste0(path_data, "/txt/UDHR")
list.files(path_udhr)  # list the files in this folder
```

Each one of these txt files contains the text of the UDHR in the specific language.
For instance, to inspect what each one of these files contain, we do the following:

```{r}
# just first 5 lines
cat(readLines(file.path(path_udhr, "UDHR_chinese.txt"), n = 5), sep = "\n")  
```

To import these files, you can use the following code:

```{r}
dat_udhr <- readtext(path_udhr)
glimpse(dat_udhr)
```

::: {.callout-note}
If you are using Windows, you need might need to specify the encoding of the file by adding `encoding = "utf-8"`. In this case, imported texts might appear like `<U+4E16><U+754C><U+4EBA><U+6743>` but they indicate that Unicode charactes are imported correctly.
:::

Here's another example of multiple text files. The directory `/txt/EU_manifestos` contains text files (".txt") of the European Union manifestos in different languages. 

```{r}
path_eu <- paste0(path_data, "/txt/EU_manifestos/")
list.files(path_eu)  # list the files in this folder
```

You can generate document-level variables based on the file names using the `docvarnames` and `docvarsfrom` argument. `dvsep = "_"` specifies the value separator in the filenames. `encoding = "ISO-8859-1"` determines character encodings of the texts. Notice how the document variables are nicely generated from the file names.

```{r}
dat_eu <- readtext(
  file = path_eu,
  docvarsfrom = "filenames", 
  docvarnames = c("unit", "context", "year", "language", "party"),
  dvsep = "_", 
  encoding = "ISO-8859-1"
)
glimpse(dat_eu)
```

### JSON

You can also read JSON files (.json) downloaded from the Twititer stream API. [twitter.json](https://raw.githubusercontent.com/quanteda/tutorials.quanteda.io/master/content/data/twitter.json) is located in data directory of this tutorial package.


```{r}
#| eval: false
dat_twitter <- readtext("../data/twitter.json", source = "twitter")
```

The file comes with several metadata for each tweet, such as the number of retweets and likes, the username, time and time zone. 


```{r}
#| eval: false
head(names(dat_twitter))
```

```
## [1] "doc_id"         "text"           "retweet_count"  "favorite_count"
## [5] "favorited"      "truncated"
```


